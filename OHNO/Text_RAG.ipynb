{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import re\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import *\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "import openai\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Get Environment settings from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Azure AI Search Index Settings\n",
    "service_endpoint = f\"{os.getenv('AZURE_SEARCH_SERVICE_ENDPOINT')}\"\n",
    "index_creds = AzureKeyCredential(os.getenv(\"AZURE_SEARCH_INDEX_KEY\"))\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME_TEXT\")\n",
    "\n",
    "## Create a client for querying the index\n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=index_creds)\n",
    "## Create an index\n",
    "index_client = SearchIndexClient(service_endpoint, index_creds)\n",
    "\n",
    "# Azure Openai Settings\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.azure_endpoint = os.getenv(\"OPENAI_API_ENDPOINT\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "\n",
    "azure_openai_client = AzureOpenAI(\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "    api_version = os.getenv(\"OPENAI_API_VERSION\"),\n",
    "    azure_endpoint = os.getenv(\"OPENAI_API_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Indexing: 101 items in total\n"
     ]
    }
   ],
   "source": [
    "def get_embedding(text, model=\"textembedding\"): # model=[Deployment Name], DONOT change this\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return azure_openai_client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "sections = []\n",
    "with open('ch1to3.csv', 'rt', newline='', encoding='utf-8', errors='ignore') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for item in csvreader:\n",
    "        section = {\n",
    "            \"id\": f\"{item[0]}-{item[1]}-{item[2]}\",\n",
    "            \"Chapter\": item[0],\n",
    "            \"Section\": item[1],\n",
    "            \"Paragraph\": item[2],\n",
    "            \"Content\": item[3],\n",
    "            \"Embedding\": get_embedding(item[3]),\n",
    "        }\n",
    "        sections.append(section)\n",
    "print(f\"Finished Indexing: {len(sections)} items in total\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.search.documents.indexes.models._index.SearchIndex at 0x1e38c2d3890>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = SearchIndex(\n",
    "    name=index_name,\n",
    "    fields=[\n",
    "        SimpleField(name=\"id\", type=\"Edm.String\", key=True),\n",
    "        SearchableField(name=\"Chapter\", type=\"Edm.String\", analyzer_name=\"standard.lucene\", \n",
    "                        filterable=True, sortable=True, facetable=True, searchable=True),\n",
    "        SearchableField(name=\"Section\", type=\"Edm.String\", analyzer_name=\"standard.lucene\",\n",
    "                        filterable=True, sortable=True, facetable=True, searchable=True),\n",
    "        SearchableField(name=\"Paragraph\", type=\"Edm.String\", analyzer_name=\"standard.lucene\",\n",
    "                        filterable=True, sortable=True, facetable=True, searchable=True),        \n",
    "        SearchableField(name=\"Content\", type=\"Edm.String\", analyzer_name=\"standard.lucene\",\n",
    "                        filterable=True, sortable=True, facetable=True, searchable=True),\n",
    "        SearchField(name=\"Embedding\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),  \n",
    "            hidden=False, searchable=True, filterable=False, sortable=False, facetable=False,\n",
    "            vector_search_dimensions=1536, vector_search_profile_name=\"my-vector-config\"),\n",
    "    ],\n",
    "    vector_search=VectorSearch(\n",
    "        profiles=[VectorSearchProfile(\n",
    "            name=\"my-vector-config\",\n",
    "            algorithm_configuration_name=\"my-hnsw\")\n",
    "        ],\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(name=\"my-hnsw\")\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "index_client.create_or_update_index(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading\n",
      "Indexed 101 sections, 101 succeeded\n"
     ]
    }
   ],
   "source": [
    "results = search_client.upload_documents(documents=sections)\n",
    "print(\"Uploading\")\n",
    "succeeded = sum([1 for r in results if r.succeeded])\n",
    "print(f\"Indexed {len(results)} sections, {succeeded} succeeded\")\n",
    "batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################\n",
      "Source: 1-1-1\n",
      "CaptionThe University of Hong Kong is now one of Hong Kong's largest single community enterprises. Each year it passes into the working life of Hong Kong and elsewhere 1,200 young graduates in a wide range of academic and professional fields. Its student enrolment is over 5,500, including some 100 candidates for doctor's degrees, and it accommodates almost I,000 of them in its halls of residence. It employs over 500 teachers of high repute, and they and their students and services occupy over 40 buildings of sizes in a range from two to 150 thousand square feet of usable area, in 70 acres of scarce land; and over 350 thousand square feet of floor space have been added in the last two years. It has a bookstock of more than half a million, including one of the largest collections there is, of perennial, ephemeral and manuscript material on Hong Kong. Its invested endowments are worth $260 millions on the market; it is spending $120 millions a year on its regular activities, four-fifths from Government subsidy.\n",
      "#########################################\n",
      "Source: 3-6-5\n",
      "CaptionAt the Court meeting held the next month Ho Kai revealed that his friend Ng Li-hing had offered to erect the two buildings at the estimated total cost of $50,000, his intention being to hand over $20,000 'in the course of the 34th year ofKwang Sui (1908-9)' and the balance over six years. Lugard had been invited to be Patron as soon as he arrived in Hong Kong and accepted. The Government was preparing the free grant of land on condition that Ng Li-hing's $20,000 was spent on buildings before the end of March 1909. Sir Paul Chater, broker and property-owner and uncle of Dr G. P. Jordan, was a member of the committee preparing to raise an endowment. Ho Kai first consulted him in the matter of the appeal, and Chater counselled delay because of the current trade depression, but promised his personal assistance when business improved. It was at this point, when a contract was about to be signed for the construction of the anatomy laboratory and museum, that Lugard's speech at St Stephen's College drew the new offer of buildings, now for a University of Hong Kong, from Chater's partner, Mody. {George Endacott, historian of Hong Kong, contributed a chapter on the University's beginnings to The First 50 rears, 1962, which I have drawn upon for some of this account}\n",
      "#########################################\n",
      "Source: 3-8-1\n",
      "CaptionInJanuary Igog Lugard prepared for use as an appeal document a memo- randum in which he set out the considerations which had developed in discussion of the project and the sort of University he expected it to be, and had it translated also into Chinese. In it he said he would appoint a Committee of Management to stay in session until a University was in being. This Committee comprised twelve members with himself in the chair, being the Anglican Bishop and the five senior Government administrative officers ex officio, among whom were May, still Rector of the College, Sir Paul Chater, Mody, Ho Kai, Wei Yuk, Lau Chu-pak, {Mr Lau was prominent among Hong Kong citizens taking a personal interest in the founding of the University, and was a founder-member of its Court and Council. His descendents have directed the Hong Kong and Yaumati Ferry Company founded by his son Tak-po}  and Cecil Clementi. Ho Kai and Wei Yuk together listed about a hundred members for a fund-raising sub-committee, and they were called together to hear an account of the scheme delivered by Lugard. Over the following months Lugard agreed to additions to the membership. With Ho Kai in the chair and Ts'o Seen-wan as principal secretary the sub-committee held weekly Sunday meetings in the Tung Wah Hospital, and formed groups among friends in Chinese cities and Chinese communities overseas, most prominent among the discussants being Ho Fook, who took an intense interest in the project. Lugard himself undertook to enlist the aid variously of Sir John Jordan, the ambassador in Peking, in seeking a contribution from the Imperial Government, the Shanghai Municipal Council whose Chairman was then David Landale, the Viceroy of the Two K wang Provinces in Canton, the Viceroy of India, a large number of Governors and other officials in Britain and South Asia and elsewhere, and the British firms.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the first library of HKU?\" #your query keywords\n",
    "query_vector = get_embedding(query)\n",
    "\n",
    "r = search_client.search(\n",
    "    search_text=None,\n",
    "    top=3,\n",
    "    vector_queries=[VectorizedQuery(\n",
    "        vector=query_vector,\n",
    "        fields=\"Embedding\"\n",
    "    )]\n",
    ")\n",
    "\n",
    "search_results = []\n",
    "for result in r:\n",
    "    print(\"#########################################\")\n",
    "    print(\"Source: \" + result[\"id\"])\n",
    "    print(\"Caption\" + result[\"Content\"])\n",
    "    search_results.append(\"Source: \" + result[\"id\"] + \"; Content: \" + result[\"Content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sources provided do not contain information on the first library of The University of Hong Kong (HKU).\n"
     ]
    }
   ],
   "source": [
    "systemMessage = \"\"\"AI Assistant that helps user to answer questions from sources provided. Be brief in your answers.\n",
    "                    Answer ONLY with the facts listed in the list of sources below. \n",
    "                    If there isn't enough information below, say you don't know. Do not generate answers that don't use the sources below. \n",
    "                    Each source has a name followed by colon and the actual information, always include the source name for each fact you use in the response. \n",
    "                    Use square brackets to reference the source, e.g. [info1.txt]. Don't combine sources, list each source separately, e.g. [info1.txt][info2.pdf].\n",
    "                \"\"\"\n",
    "\n",
    "messages = [\n",
    "    {'role' : 'system', 'content' : systemMessage},\n",
    "    {'role' : 'user', 'content' : query + \"   Source:\" + \" \".join(search_results)}\n",
    "]\n",
    "\n",
    "chat_completion = openai.chat.completions.create(\n",
    "    model=\"summer\", # Do not edit this. model=\"deployment_name\"\n",
    "    messages=messages, \n",
    "    temperature=0.7, \n",
    "    max_tokens=1024, \n",
    "    n=1)\n",
    "\n",
    "chat_content = chat_completion.choices[0].message.content\n",
    "print(chat_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "histdemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
